# Dukascopy MT4 Data Pipeline Configuration
#
# This configuration file controls the behavior of the Dukascopy MT4 data processing suite,
# including downloading, transforming, aggregating, and resampling historical and live market data.
#
# Sections:
# 1. aggregate: Controls input/output paths for aggregation.
# 2. download: Retry/backoff settings, timeouts, rate limits, and paths for historical/live downloads.
# 3. transform: Time-shifting, rounding, input/output paths, and preparation for aggregation/resampling.
# 4. resample: Batch size, rounding precision, multi-timeframe resampling rules, and per-symbol overrides.
#
# Purpose:
# - Automate crash-resilient ETL pipelines for financial market data.
# - Support incremental updates with strict time-bin alignment across multiple timeframes.
# - Allow flexibility for various asset classes (forex, commodities, indices, crypto, bonds).
#
# Usage:
# - Imported by ETL scripts to configure paths, timeframes, rate limits, and resampling rules.
# - Customization per instrument or timeframe via the `symbols` section.
#
# Note:
# - Under development; features/settings may change.
# - Paths are relative to project root unless specified otherwise.

# Below you will find the configuration for the aggregate.py script. 
aggregate:
  paths:
    data: data/aggregate/1m           # Output path for aggregate
    source: data/transform/1m         # Input path for aggregate

## Below you will find the configuration for the builder script
builder:
  paths:
    data: data                        # Input path for builder
    temp: data/temp/builder           # Temporary path for builder

# Below you will find the configuration for the download.py script. 
download:
  max_retries: 3                      # Number of retries before downloader raises
  backoff_factor: 2                   # Exponential backoff factor (wait time)
  timeout: 10                         # Request timeout
  rate_limit_rps: 1                   # Protect end-point (number of cores * rps = requests/second)
  paths:
    historic: cache                   # Historical downloads
    live: data/temp                   # Live downloads

# Below you will find the configuration for the transform.py script. 
transform:
  time_shift_ms: 7200000              # How many milliseconds should we shift (0=UTC, 7200000=GMT+2 (eg MT4 Dukascopy) )
  round_decimals: 8                   # Number of decimals to round OHLCV to
  fsync: false                        # Force flush to disk after each transformation
  validate: false                     # Force validation of OHLCV values
  paths:
    data: data/transform/1m           # Output directory for transform
    historic: cache                   # Historical downloads
    live: data/temp                   # Live downloads
  timezones:
    includes:
    - config/dukascopy/timezones/*.yaml
  symbols:
    includes:
    - config/dukascopy/processing.yaml

# Below you will find the configuration for the resample.py script. 
resample:
  round_decimals: 8                   # Number of decimals to round OHLCV to
  batch_size: 250000                  # Maximum number of lines to read per batch
  fsync: false                        # Force flush to disk after each batch
  paths:
    data: data/resample               # Output directory for resampled timeframes
  timeframes:
    includes:
    - config/dukascopy/timeframes/default.yaml
  # Support per symbol overrides
  symbols:
    includes:
    - config/dukascopy/timeframes/bonds.yaml
    - config/dukascopy/timeframes/commodities.yaml
    - config/dukascopy/timeframes/indices/*.yaml
