# Dukascopy MT4 Data Pipeline Configuration
#
# This configuration file controls the behavior of the Dukascopy MT4 data processing suite,
# including downloading, transforming, aggregating, and resampling historical and live market data.
#
# Sections:
# 1. aggregate: Controls input/output paths for aggregation.
# 2. download: Retry/backoff settings, timeouts, rate limits, and paths for historical/live downloads.
# 3. transform: Time-shifting, rounding, input/output paths, and preparation for aggregation/resampling.
# 4. resample: Batch size, rounding precision, multi-timeframe resampling rules, and per-symbol overrides.
# 5. builder: Path configuration for CSV/Parquet builder tool
#
# Purpose:
# - Automate crash-resilient ETL pipelines for financial market data.
# - Support incremental updates with strict time-bin alignment across multiple timeframes.
# - Allow flexibility for various asset classes (forex, commodities, indices, crypto, bonds).
#
# Usage:
# - Imported by ETL scripts to configure paths, timeframes, rate limits, and resampling rules.
# - Customization per instrument or timeframe via the `symbols` section.
#
# Note:
# - Under development; features/settings may change.
# - Paths are relative to project root unless specified otherwise.
# - Fsync is more integrity but impacts performance quite a bit
#   Advice: during initial full run, disable, enable in incremental mode.
#
# fsync: Force physical disk synchronization after every file write (Gemini).
# 
# Set to 'true' for:
#   - Live trading environments where every candle is critical.
#   - Environments prone to power failure or OS crashes.
#   - Shared network drives (NAS/NFS) where data persistence is managed remotely.
# 
# Set to 'false' (Default) for:
#   - Bulk historical rebuilds (massive performance gain).
#   - Local SSDs where data can be easily regenerated if a crash occurs.
#   - Minimizing wear on consumer-grade SSDs.
#
# Below you will find the configuration for the aggregate.py script. 
aggregate:
  fsync: false                        # Force flush to disk after each aggregation
  fmode: binary                       # Only binary is supported from v0.6.6 onward
  paths:
    data: data/aggregate/1m           # Output path for aggregate
    source: data/transform/1m         # Input path for aggregate

## Below you will find the configuration for the builder script
builder:
  fmode: binary                       # Only binary is supported from v0.6.6 onward
  paths:
    data: data                        # Input path for builder
    temp: data/temp/builder           # Temporary path for builder

# Below you will find the configuration for the download.py script. 
download:
  max_retries: 3                      # Number of retries before downloader raises
  backoff_factor: 2                   # Exponential backoff factor (wait time)
  timeout: 10                         # Request timeout
  rate_limit_rps: 1                   # Protect end-point (number of cores * rps = requests/second)
  paths:
    historic: cache                   # Historical downloads
    live: data/temp                   # Live downloads

## Below you will find the configuration for the http service script.
http:
  poolmode: thread                    # Poolmode indicator calculations (process/thread)
  fmode: binary                       # Only binary is supported from v0.6.6 onward
  docs: config/dukascopy/http-docs    # Directory where HTML docs will live
  listen: ":8000"                     # Listen to this port

## Below you will find the configuration for the orchestrator script
orchestrator:
  # num_processes: 8                  # Override maximum number of cores to use
  disable_download: 0                 # Option to disable downloading
  paths:
    downloads: cache                  # Output path for downloads
    locks: data/locks                 # Lock files are stored here
    transforms: data/transform/1m     # Output path for transform

# Below you will find the configuration for the transform.py script. 
transform:
  time_shift_ms: 7200000              # How many milliseconds should we shift (0=UTC, 7200000=GMT+2 (eg MT4 Dukascopy) )
  round_decimals: 8                   # Number of decimals to round OHLCV to
  fsync: false                        # Force flush to disk after each transformation
  fmode: binary                       # Only binary is supported from v0.6.6 onward
  validate: false                     # Force validation of OHLCV values
  paths:
    data: data/transform/1m           # Output directory for transform
    historic: cache                   # Historical downloads
    live: data/temp                   # Live downloads
  timezones:
    includes:
    - config/dukascopy/timezones/*.yaml
  symbols:
    includes:
    - config/dukascopy/processing.yaml

# Below you will find the configuration for the resample.py script. 
resample:
  round_decimals: 8                   # Number of decimals to round OHLCV to
  batch_size: 250000                  # Maximum number of lines to read per batch
  fsync: false                        # Force flush to disk after each batch
  fmode: binary                       # Only binary is supported from v0.6.6 onward
  paths:
    data: data/resample               # Output directory for resampled timeframes
  timeframes:
    includes:
    - config/dukascopy/timeframes/default.yaml
  # Support per symbol overrides
  symbols:
    includes:
    - config/dukascopy/timeframes/bonds.yaml
    - config/dukascopy/timeframes/commodities.yaml
    - config/dukascopy/timeframes/stocks.yaml
    - config/dukascopy/timeframes/indices/*.yaml
    


