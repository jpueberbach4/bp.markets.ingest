name: "Daily Traffic Logger"

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  update-stats:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.TRAFFIC_ACTION_TOKEN }}

      - name: Fetch Traffic Data
        uses: sangonzal/repository-traffic-action@v.0.1.6
        env:
          TRAFFIC_ACTION_TOKEN: ${{ secrets.TRAFFIC_ACTION_TOKEN }}

      - name: Merge Stats
        run: |
          mkdir -p .github/traffic
          cat << 'EOF' > merge_stats.py
          import csv
          import os

          def merge_csv(name):
              new_path = f'traffic/{name}.csv'
              old_path = f'.github/traffic/{name}.csv'
              if not os.path.exists(new_path): return
              
              data = {}
              fieldnames = []

              # Helper to get the first column name (e.g., _date or date)
              def get_id_col(reader):
                  return reader.fieldnames[0] if reader.fieldnames else None

              # Load old data
              if os.path.exists(old_path) and os.path.getsize(old_path) > 0:
                  with open(old_path, 'r', newline='') as f:
                      reader = csv.DictReader(f)
                      id_col = get_id_col(reader)
                      if id_col:
                          fieldnames = reader.fieldnames
                          for row in reader:
                              if row.get(id_col):
                                  data[row[id_col]] = row
              
              # Load new data
              with open(new_path, 'r', newline='') as f:
                  reader = csv.DictReader(f)
                  id_col = get_id_col(reader)
                  if id_col:
                      fieldnames = reader.fieldnames # Prefer new fieldnames if they changed
                      for row in reader:
                          if row.get(id_col):
                              data[row[id_col]] = row
              
              if not data or not fieldnames: return

              # Write combined results
              id_col = fieldnames[0]
              sorted_keys = sorted(data.keys())
              with open(old_path, 'w', newline='') as f:
                  writer = csv.DictWriter(f, fieldnames=fieldnames)
                  writer.writeheader()
                  for k in sorted_keys:
                      writer.writerow(data[k])

          merge_csv('clones')
          merge_csv('views')
          EOF
          python3 merge_stats.py
          if [ -d "traffic" ]; then
            cp traffic/*.png .github/traffic/ 2>/dev/null || true
          fi
          
          sudo rm -rf traffic merge_stats.py
      - name: Commit and Push
        uses: Endbug/add-and-commit@v9
        with:
          author_name: "GitHub Action"
          author_email: "action@github.com"
          message: "Update stats [skip ci]"
          add: ".github/traffic/*"
          pull: '--rebase --autostash'